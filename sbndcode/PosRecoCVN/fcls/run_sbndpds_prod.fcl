#include "services_sbnd.fcl"
#include "simulationservices_sbnd.fcl"
#include "messages_sbnd.fcl"
#include "sam_sbnd.fcl"

process_name: SBNDPDSProd

services:
{
  TFileService:              { fileName: "service_histos.root" }
  @table::sbnd_basic_services
  @table::sbnd_simulation_services
  ParticleInventoryService: @local::sbnd_particleinventoryservice
  BackTrackerService:       @local::sbnd_backtrackerservice
  ParticleInventoryService: @local::standard_particleinventoryservice
}

source:
{
  module_type: RootInput
  maxEvents:  -1  # Number of events to create
}

physics:
{
  producers:
  {
    opanatree: {
      module_type: "SBNDPDSProducer"
      Verbosity: 1
      MCTruthModuleLabel: ["generator"]
      MCTruthInstanceLabel: [""]
      MCTruthOrigin: [1, 4]  # BNB neutrinos and single particles
      MCTruthPDG: [12, 14, -12, -14]  # neutrinos
      MCModuleLabel: "largeant"
      OpHitsModuleLabel: ["ophitpmt","ophitxarapuca"]
      OpFlashesModuleLabel: ["opflashtpc0", "opflashtpc1", "opflashtpc0xarapuca", "opflashtpc1xarapuca"]
      G4BufferBoxX: [-300, 300] #cm
      G4BufferBoxY: [-400, 400] #cm
      G4BufferBoxZ: [-100, 600] #cm
      G4BeamWindow: [-10000, 12000] #ns
      KeepPDGCode: []  # empty = keep all particles
      SaveOpHits: true
      
      # TensorFlow Configuration
      RunInference: true  # Set to true to enable TensorFlow inference
      ModelPath: "/exp/sbnd/data/users/svidales/AI_nuvT_project_support/cnn_models/test_larsoft_inference_savedmodel_resnet18"       # Path to TensorFlow SavedModel directory
      InputNames: []      # Leave empty to use default model inputs
      OutputNames: []     # Leave empty to use default model outputs
    }
  }

  # Definir paths
  prod: [opanatree]
  stream: [out1]
  
  # Configurar trigger_paths y end_paths
  trigger_paths: [prod]
  end_paths: [stream]
}

outputs:
{
  out1:
  {
    module_type: RootOutput
    fileName: "pixelmap_variables.root"
    outputCommands: [
      "drop *",
      "keep PixelMapVars_opanatree__SBNDPDSProd"
    ]
  }
}

